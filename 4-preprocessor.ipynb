{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import Levenshtein as lev\n",
    "from jiwer import wer\n",
    "import string\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove ellipses from the text\n",
    "    text = text.replace(\"…\", \"\")\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Convert Turkish characters to lowercase\n",
    "    turkish_lower_map = str.maketrans(\"İI\", \"iı\")\n",
    "    text = text.translate(turkish_lower_map).lower()\n",
    "    return text\n",
    "\n",
    "def remove_first_char(text):\n",
    "    return text\n",
    "    return text[1:] if text else text # if using the whisper model please use this return statement, if using the finetuned model please use the above return statement\n",
    "\n",
    "def levenshtein_distance(s1, s2):\n",
    "    return lev.distance(s1, s2)\n",
    "\n",
    "# Define a function to convert numbers to Turkish text\n",
    "# this algorithm works like Roman numerals, it converts the number to text\n",
    "def number_to_turkish_text(number):\n",
    "    units = [\"\", \"bir\", \"iki\", \"üç\", \"dört\", \"beş\", \"altı\", \"yedi\", \"sekiz\", \"dokuz\"]\n",
    "    tens = [\"\", \"on\", \"yirmi\", \"otuz\", \"kırk\", \"elli\", \"altmış\", \"yetmiş\", \"seksen\", \"doksan\"]\n",
    "    \n",
    "    number = str(number)\n",
    "    length = len(number)\n",
    "    \n",
    "    if length == 1:\n",
    "        return units[int(number)]\n",
    "    elif length == 2:\n",
    "        return tens[int(number[0])] + \" \" + units[int(number[1])]\n",
    "    elif length == 3:\n",
    "        if number[1:] == \"00\":\n",
    "            return units[int(number[0])] + \" yüz\"\n",
    "        else:\n",
    "            return units[int(number[0])] + \" yüz \" + number_to_turkish_text(number[1:])\n",
    "    elif length == 4:\n",
    "        if number[1:] == \"000\":\n",
    "            return units[int(number[0])] + \" bin\"\n",
    "        else:\n",
    "            return units[int(number[0])] + \" bin \" + number_to_turkish_text(number[1:])\n",
    "    else:\n",
    "        return number\n",
    "\n",
    "def convert_numbers_to_text(text):\n",
    "    # Pattern to match numbers with optional punctuation after the number\n",
    "    pattern = re.compile(r\"(\\d+)([.,']*)\")\n",
    "    converted_text = []\n",
    "\n",
    "    ordinal_suffixes = {\n",
    "        '0': 'sıfırıncı', '1': 'birinci', '2': 'ikinci', '3': 'üçüncü',\n",
    "        '4': 'dördüncü', '5': 'beşinci', '6': 'altıncı', '7': 'yedinci',\n",
    "        '8': 'sekizinci', '9': 'dokuzuncu'\n",
    "    }\n",
    "    \n",
    "    pattern_percentage = re.compile(r\"%(\\d+)\")\n",
    "\n",
    "    # Find and replace percentages\n",
    "    for match in pattern_percentage.finditer(text):\n",
    "        percentage = match.groups()\n",
    "        number = int(percentage[0])\n",
    "        converted_number = number_to_turkish_text(number)\n",
    "        text = text.replace(match.group(), f\"yüzde {converted_number}\", 1)\n",
    "\n",
    "    # Find and replace numbers with punctuation after the number\n",
    "    for match in pattern.finditer(text):\n",
    "        number, punct = match.groups()\n",
    "        converted_number = number_to_turkish_text(number)\n",
    "        if punct == '.':\n",
    "            if number in ordinal_suffixes:\n",
    "                converted_text.append(ordinal_suffixes[number])\n",
    "            else:\n",
    "                converted_text.append(converted_number + \"ıncı\")\n",
    "        else:\n",
    "            converted_text.append(converted_number + punct)\n",
    "    \n",
    "    # Replace matched patterns with their converted forms\n",
    "    for original, converted in zip(pattern.findall(text), converted_text):\n",
    "        text = text.replace(''.join(original), converted, 1)\n",
    "\n",
    "    return text\n",
    "\n",
    "def handle_special_apostrophes(text):\n",
    "    words_to_replace = {\n",
    "        \"dört'ü\": \"dördü\",\n",
    "    }\n",
    "    for word, replacement in words_to_replace.items():\n",
    "        text = text.replace(word, replacement)\n",
    "    # Remove other apostrophes\n",
    "    text = text.replace(\"'\", \"\")\n",
    "    return text\n",
    "\n",
    "# Load the results dataframe\n",
    "df = pd.read_csv('transcription_results_larger_than_50_tr_250_finetuned_whisper.csv')\n",
    "\n",
    "# Convert numbers in transcriptions to text\n",
    "df['transcription'] = df['transcription'].apply(convert_numbers_to_text)\n",
    "\n",
    "# Handle special apostrophes in transcriptions\n",
    "df['transcription'] = df['transcription'].apply(handle_special_apostrophes)\n",
    "\n",
    "# Preprocess the expected and actual transcriptions\n",
    "df['expected_transcription'] = df['expected_transcription'].apply(preprocess_text)\n",
    "df['transcription'] = df['transcription'].apply(preprocess_text)\n",
    "\n",
    "# Remove the first character from the transcriptions\n",
    "df['transcription'] = df['transcription'].apply(remove_first_char)\n",
    "\n",
    "# Calculate Levenshtein distance and word error rate\n",
    "df['levenshtein_distance'] = df.apply(lambda row: levenshtein_distance(row['expected_transcription'], row['transcription']), axis=1)\n",
    "df['word_error_rate'] = df.apply(lambda row: wer(row['expected_transcription'], row['transcription']), axis=1)\n",
    "\n",
    "# Save the results with metrics to a new CSV file\n",
    "df.to_csv('transcription_results_with_metrics_50_tr_md2.csv', index=False)\n",
    "\n",
    "# Print the results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"word_error_rate\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"levenshtein_distance\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['expected_transcription'].apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['expected_transcription'].apply(len).mean() / df['transcription'].apply(len).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
